{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"mount_file_id":"1ZopIX4yZycrNs1q_06-AGoINNc6uQb8x","authorship_tag":"ABX9TyNcN8Ls8eMpKHEXDl8HYj+3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install torch torchvision torchaudio numpy pandas scikit-learn"],"metadata":{"id":"xonaxwRgOdZo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"HXy5XWewy2Cn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Import necessary libraries\n","import pandas as pd\n","from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n","import tensorflow as tf\n","from tensorflow.keras.layers import Input, Embedding, Dense, Flatten, Concatenate, Dropout\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","import pickle\n","\n","# 1. 데이터 로드\n","user_data_file = '/content/drive/MyDrive/shinhan_data/realistic_korean_financial_user_data.csv'\n","loan_application_file = '/content/drive/MyDrive/shinhan_data/realistic_korean_loan_applications.csv'\n","loan_product_file = '/content/drive/MyDrive/shinhan_data/realistic_korean_credit_loan_products.csv'\n","\n","user_data_df = pd.read_csv(user_data_file)\n","loan_applications_df = pd.read_csv(loan_application_file)\n","loan_products_df = pd.read_csv(loan_product_file)\n","\n","# 2. 데이터 전처리\n","\n","# Combine the user and loan data based on the loan application data\n","df = loan_applications_df.merge(user_data_df, on='user_id').merge(loan_products_df, on='loan_id')\n","\n","# Separate features into categorical and numerical\n","categorical_features = ['user_id', 'loan_id', 'gender', 'region', 'occupation', 'late_payment', 'financial_accident']\n","numerical_features = ['age', 'annual_income', 'debt', 'credit_score', 'annual_spending', 'num_cards',\n","                      'interest_rate', 'loan_limit', 'loan_term_months', 'credit_score_requirement','total_deposit', 'total_savings','total_assets']\n","\n","# Label encoding for categorical features\n","label_encoders = {}\n","for feature in categorical_features:\n","    le = LabelEncoder()\n","    df[feature] = le.fit_transform(df[feature])\n","    label_encoders[feature] = le\n","\n","# Normalize numerical features\n","scaler = MinMaxScaler()\n","df[numerical_features] = scaler.fit_transform(df[numerical_features])\n","\n","# Save the LabelEncoders and Scaler to a pickle file\n","preprocessing_dict = {\n","    'label_encoders': label_encoders,\n","    'scaler': scaler,\n","    'categorical_features': categorical_features,\n","    'numerical_features': numerical_features\n","}\n","\n","with open('loan_preprocessing.pkl', 'wb') as f:\n","    pickle.dump(preprocessing_dict, f)\n","\n","# Prepare inputs for the model\n","X_categorical = [df[feature].values for feature in categorical_features]\n","X_numerical = df[numerical_features].values\n","y = df['loan_applied'].values\n","\n","# 3. DeepFM 모델 정의\n","\n","# Define input layers for categorical and numerical features\n","input_layers = []\n","embedding_layers = []\n","\n","for feature in categorical_features:\n","    input_layer = Input(shape=(1,), name=feature)\n","    embedding_layer = Embedding(input_dim=df[feature].nunique(), output_dim=4, name=f\"{feature}_embedding\")(input_layer)\n","    embedding_layer = Flatten()(embedding_layer)\n","    input_layers.append(input_layer)\n","    embedding_layers.append(embedding_layer)\n","\n","# Numerical features input\n","numerical_input = Input(shape=(len(numerical_features),), name='numerical_input')\n","input_layers.append(numerical_input)\n","embedding_layers.append(numerical_input)\n","\n","# Concatenate all embeddings and numerical features\n","concatenated = Concatenate()(embedding_layers)\n","\n","# Deep part of the model\n","from tensorflow.keras.regularizers import l2\n","\n","x = Dense(64, activation='relu', kernel_regularizer=l2(0.01))(concatenated)\n","x = Dropout(0.4)(x)\n","x = Dense(32, activation='relu', kernel_regularizer=l2(0.01))(x)\n","x = Dropout(0.4)(x)\n","\n","# Output layer\n","output = Dense(1, activation='sigmoid')(x)\n","\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n","model = Model(inputs=input_layers, outputs=output)\n","model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Train the model\n","history = model.fit(X_categorical + [X_numerical], y, epochs=10, batch_size=32, validation_split=0.2, callbacks=[early_stopping])\n","\n","# Save the trained model\n","model.save('loan_deepfm_model.h5')\n"],"metadata":{"id":"-eNScl_yH7MY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 기존 카테고리에 없는 새로운 값을 처리하기 위한 함수\n","def encode_with_unknown_handling(feature, encoder, value):\n","    if value in encoder.classes_:\n","        return encoder.transform([value])[0]\n","    else:\n","        # 새로운 값에 대해 '미지정' 또는 다른 대체 값을 사용하도록 처리\n","        return encoder.transform([encoder.classes_[0]])[0]  # 첫 번째 클래스로 대체\n","\n","# 예측 수행을 위한 전처리 및 데이터 보완\n","def preprocess_and_predict(new_user_data, model, label_encoders, scaler, categorical_features, numerical_features, loan_products_df):\n","    # loan_id로부터 나머지 대출 상품 정보를 가져옴\n","    loan_info = get_loan_product_info(new_user_data['loan_id'][0], loan_products_df)\n","\n","    # 새로운 데이터에 대출 상품 정보 추가\n","    new_user_data['interest_rate'] = [loan_info['interest_rate']]\n","    new_user_data['loan_limit'] = [loan_info['loan_limit']]\n","    new_user_data['loan_term_months'] = [loan_info['loan_term_months']]\n","    new_user_data['credit_score_requirement'] = [loan_info['credit_score_requirement']]\n","\n","    # 1. Label Encoding: 새로운 데이터에 대해 이전에 학습된 LabelEncoder 적용\n","    for feature in categorical_features:\n","        if feature in label_encoders:\n","            new_user_data[feature] = new_user_data[feature].apply(lambda x: encode_with_unknown_handling(feature, label_encoders[feature], x))\n","\n","    # 2. Normalize numerical features\n","    new_user_data[numerical_features] = scaler.transform(new_user_data[numerical_features])\n","\n","    # 3. Prepare input for prediction\n","    X_categorical = [new_user_data[feature].values for feature in categorical_features]\n","    X_numerical = new_user_data[numerical_features].values\n","\n","    # 4. Predict using the trained model\n","    prediction = model.predict(X_categorical + [X_numerical])\n","\n","    return prediction\n","\n","# 여러 loan_id에 대해 예측을 수행하고, 가장 높은 선택 확률을 가지는 대출 상품을 찾는 함수\n","def find_best_loan_product(new_user_data, model, label_encoders, scaler, categorical_features, numerical_features, loan_products_df):\n","    best_loan_id = None\n","    best_prediction = 0.0\n","\n","    for loan_id in loan_products_df['loan_id'].unique():\n","        # 현재 loan_id에 대한 대출 상품 정보 추가\n","        new_user_data['loan_id'] = [loan_id]\n","\n","        # loan_id에 해당하는 대출 상품 정보를 가져와서 new_user_data에 추가\n","        loan_info = get_loan_product_info(loan_id, loan_products_df)\n","        new_user_data['interest_rate'] = [loan_info['interest_rate']]\n","        new_user_data['loan_limit'] = [loan_info['loan_limit']]\n","        new_user_data['loan_term_months'] = [loan_info['loan_term_months']]\n","        new_user_data['credit_score_requirement'] = [loan_info['credit_score_requirement']]\n","\n","        # 예측 수행\n","        prediction = preprocess_and_predict(new_user_data, model, label_encoders, scaler, categorical_features, numerical_features, loan_products_df)\n","\n","        if prediction[0][0] > best_prediction:\n","            best_prediction = prediction[0][0]\n","            best_loan_id = loan_id\n","\n","    return best_loan_id, best_prediction\n","\n","# 새로운 사용자 데이터\n","new_user_data = pd.DataFrame({\n","    'user_id': [100005],  # 새 유저의 ID\n","    'gender': [1],  # 성별\n","    'region': ['서울'],  # 지역\n","    'occupation': ['무직'],  # 직업\n","    'late_payment': [0],  # 연체 여부\n","    'financial_accident': [0],  # 금융 사고 여부\n","    'age': [40],  # 나이\n","    'annual_income': [1500],  # 연간 소득\n","    'debt': [300],  # 부채\n","    'credit_score': [750],  # 신용 점수\n","    'annual_spending': [1000],  # 연간 소비\n","    'num_cards': [1],  # 보유 카드 수\n","    'total_deposit': [0],\n","    'total_savings': [500],\n","    'total_assets': [200]\n","})\n","\n","# 모든 대출 상품 중에서 가장 선택할 확률이 높은 대출 상품 찾기\n","best_loan_id, best_prediction = find_best_loan_product(new_user_data, model, label_encoders, scaler, categorical_features, numerical_features, loan_products_df)\n","print(f\"가장 선택할 확률이 높은 대출 상품 ID: {best_loan_id}, 선택 확률: {best_prediction}\")\n"],"metadata":{"id":"Pfauxx9eCsQq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n","import tensorflow as tf\n","from tensorflow.keras.layers import Input, Embedding, Dense, Flatten, Concatenate, Dropout\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","import pickle\n","\n","# 1. 데이터 로드\n","user_data_file = '/content/drive/MyDrive/shinhan_data/realistic_korean_financial_user_data.csv'\n","saving_product_file = '/content/drive/MyDrive/shinhan_data/realistic_korean_savings_products.csv'\n","saving_application_file = '/content/drive/MyDrive/shinhan_data/realistic_korean_savings_applications.csv'\n","\n","user_data_df = pd.read_csv(user_data_file)\n","saving_applications_df = pd.read_csv(saving_application_file)\n","saving_products_df = pd.read_csv(saving_product_file)\n","\n","# 2. 데이터 전처리\n","# Combine the user and savings data based on the savings application data\n","df = saving_applications_df.merge(user_data_df, on='user_id').merge(saving_products_df, on='savings_id')\n","\n","# Separate features into categorical and numerical\n","categorical_features = ['user_id', 'savings_id', 'gender', 'region', 'occupation', 'late_payment', 'financial_accident']\n","numerical_features = ['age', 'annual_income', 'debt', 'credit_score', 'annual_spending', 'num_cards',\n","                      'savings_interest_rate', 'term_months', 'min_savings_amount', 'max_savings_amount']\n","\n","# Label encoding for categorical features\n","label_encoders = {}\n","for feature in categorical_features:\n","    le = LabelEncoder()\n","    df[feature] = le.fit_transform(df[feature])\n","    label_encoders[feature] = le\n","\n","# Normalize numerical features\n","scaler = MinMaxScaler()\n","df[numerical_features] = scaler.fit_transform(df[numerical_features])\n","\n","# Save the LabelEncoders and Scaler to a pickle file\n","preprocessing_dict = {\n","    'label_encoders': label_encoders,\n","    'scaler': scaler,\n","    'categorical_features': categorical_features,\n","    'numerical_features': numerical_features\n","}\n","\n","with open('savings_preprocessing.pkl', 'wb') as f:\n","    pickle.dump(preprocessing_dict, f)\n","\n","# Prepare inputs for the model\n","X_categorical = [df[feature].values for feature in categorical_features]\n","X_numerical = df[numerical_features].values\n","y = df['savings_applied'].values  # 예적금 상품에 대한 응답\n","\n","# DeepFM 모델 정의\n","def build_savings_deepfm_model(input_dim, categorical_dims, embed_dim=8):\n","    inputs = []\n","    embeddings = []\n","\n","    # Embedding for categorical features\n","    for dim in categorical_dims:\n","        input_layer = Input(shape=(1,))\n","        embedding = Embedding(input_dim=dim, output_dim=embed_dim)(input_layer)\n","        embedding = Flatten()(embedding)\n","        inputs.append(input_layer)\n","        embeddings.append(embedding)\n","\n","    # Numerical features input\n","    numerical_input = Input(shape=(len(numerical_features),))\n","    inputs.append(numerical_input)\n","    embeddings.append(numerical_input)\n","\n","    # Concatenate all embeddings and numerical features\n","    concatenated = Concatenate()(embeddings)\n","\n","    # Deep part of the model\n","    x = Dense(64, activation='relu')(concatenated)\n","    x = Dropout(0.5)(x)\n","    x = Dense(32, activation='relu')(x)\n","    x = Dropout(0.3)(x)\n","    output = Dense(1, activation='sigmoid')(x)\n","\n","    model = Model(inputs=inputs, outputs=output)\n","    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n","\n","    return model\n","\n","categorical_dims = [df[feature].nunique() for feature in categorical_features]\n","model = build_savings_deepfm_model(len(X_categorical) + len(X_numerical), categorical_dims)\n","early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n","\n","# 모델 학습\n","model.fit(X_categorical + [X_numerical], y, epochs=10, batch_size=32, validation_split=0.2, callbacks=[early_stopping])\n","\n","# 학습된 모델 저장\n","model.save('savings_deepfm_model.h5')\n"],"metadata":{"id":"R63hzKSRJKMX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 기존 카테고리에 없는 새로운 값을 처리하기 위한 함수\n","def encode_with_unknown_handling(feature, encoder, value):\n","    if value in encoder.classes_:\n","        return encoder.transform([value])[0]\n","    else:\n","        # 새로운 값에 대해 '미지정' 또는 다른 대체 값을 사용하도록 처리\n","        return encoder.transform([encoder.classes_[0]])[0]  # 첫 번째 클래스로 대체\n","\n","# 예적금 상품 정보를 가져오는 함수\n","def get_saving_product_info(saving_id, saving_products_df):\n","    return saving_products_df[saving_products_df['savings_id'] == saving_id].iloc[0]\n","\n","# 예측 수행을 위한 전처리 및 데이터 보완\n","def preprocess_and_predict(new_user_data, model, label_encoders, scaler, categorical_features, numerical_features):\n","    # 1. Label Encoding: 새로운 데이터에 대해 이전에 학습된 LabelEncoder 적용\n","    for feature in categorical_features:\n","        if feature in label_encoders:\n","            new_user_data[feature] = new_user_data[feature].apply(lambda x: encode_with_unknown_handling(feature, label_encoders[feature], x))\n","\n","    # 2. Normalize numerical features\n","    new_user_data[numerical_features] = scaler.transform(new_user_data[numerical_features])\n","\n","    # 3. Prepare input for prediction\n","    X_categorical = [new_user_data[feature].values for feature in categorical_features]\n","    X_numerical = new_user_data[numerical_features].values\n","\n","    # 4. Predict using the trained model\n","    prediction = model.predict(X_categorical + [X_numerical])\n","\n","    return prediction\n","\n","# 여러 saving_id에 대해 예측을 수행하고, 가장 높은 선택 확률을 가지는 예적금 상품을 찾는 함수\n","def recommend_saving_product(new_user_data, model, label_encoders, scaler, categorical_features, numerical_features, saving_products_df):\n","    best_saving_id = None\n","    best_prediction = 0.0\n","\n","    for saving_id in saving_products_df['savings_id'].unique():\n","        # 현재 saving_id에 대한 예적금 상품 정보 추가\n","        saving_info = get_saving_product_info(saving_id, saving_products_df)\n","        new_user_data['savings_id'] = [saving_id]\n","        new_user_data['savings_interest_rate'] = [saving_info['savings_interest_rate']]\n","        new_user_data['term_months'] = [saving_info['term_months']]\n","        new_user_data['min_savings_amount'] = [saving_info['min_savings_amount']]\n","        new_user_data['max_savings_amount'] = [saving_info['max_savings_amount']]\n","\n","        # 예측 수행\n","        prediction = preprocess_and_predict(new_user_data, model, label_encoders, scaler, categorical_features, numerical_features)\n","\n","        if prediction[0][0] > best_prediction:\n","            best_prediction = prediction[0][0]\n","            best_saving_id = saving_id\n","\n","    return best_saving_id, best_prediction\n","\n","# 새로운 사용자 데이터\n","new_user_data = pd.DataFrame({\n","    'user_id': [100001],  # 새 유저의 ID\n","    'gender': [1],  # 성별\n","    'region': ['서울'],  # 지역\n","    'occupation': ['대기업 직원'],  # 직업\n","    'late_payment': [0],  # 연체 여부\n","    'financial_accident': [0],  # 금융 사고 여부\n","    'age': [42],  # 나이\n","    'annual_income': [4000],  # 연간 소득\n","    'debt': [2000],  # 부채\n","    'credit_score': [750],  # 신용 점수\n","    'annual_spending': [2000],  # 연간 소비\n","    'num_cards': [2],  # 보유 카드 수\n","    'min_balance': [100]  # 최소 잔액\n","})\n","\n","# 모든 예적금 상품 중에서 가장 선택할 확률이 높은 예적금 상품 찾기\n","best_saving_id, best_prediction = recommend_saving_product(new_user_data, model, label_encoders, scaler, categorical_features, numerical_features, saving_products_df)\n","print(f\"가장 추천할 예적금 상품 ID: {best_saving_id}, 선택 확률: {best_prediction}\")\n"],"metadata":{"id":"xOdGai_ggRS7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pickle\n","\n","# 1. 데이터 로드\n","user_data_file = '/content/drive/MyDrive/shinhan_data/realistic_korean_financial_user_data.csv'\n","deposit_product_file = '/content/drive/MyDrive/shinhan_data/realistic_korean_deposit_products.csv'\n","deposit_application_file = '/content/drive/MyDrive/shinhan_data/realistic_korean_deposit_applications.csv'\n","\n","user_data_df = pd.read_csv(user_data_file)\n","deposit_applications_df = pd.read_csv(deposit_application_file)\n","deposit_products_df = pd.read_csv(deposit_product_file)\n","\n","# 2. 데이터 전처리\n","# Combine the user and deposit data based on the deposit application data\n","df = deposit_applications_df.merge(user_data_df, on='user_id').merge(deposit_products_df, on='deposit_id')\n","\n","# Separate features into categorical and numerical\n","categorical_features = ['user_id', 'deposit_id', 'gender', 'region', 'occupation', 'late_payment', 'financial_accident']\n","numerical_features = ['age', 'annual_income', 'debt', 'credit_score', 'annual_spending', 'num_cards',\n","                      'deposit_interest_rate', 'term_months', 'min_deposit_amount', 'max_deposit_amount']\n","\n","# Label encoding for categorical features\n","label_encoders = {}\n","for feature in categorical_features:\n","    le = LabelEncoder()\n","    df[feature] = le.fit_transform(df[feature])\n","    label_encoders[feature] = le\n","\n","# Normalize numerical features\n","scaler = MinMaxScaler()\n","df[numerical_features] = scaler.fit_transform(df[numerical_features])\n","\n","# Prepare inputs for the model\n","X_categorical = [df[feature].values for feature in categorical_features]\n","X_numerical = df[numerical_features].values\n","y = df['deposit_applied'].values  # 예금 상품에 대한 응답\n","\n","# LabelEncoders와 Scaler를 pickle로 저장\n","preprocessing_dict = {\n","    'label_encoders': label_encoders,\n","    'scaler': scaler,\n","    'categorical_features': categorical_features,\n","    'numerical_features': numerical_features\n","}\n","\n","with open('deposit_preprocessing.pkl', 'wb') as f:\n","    pickle.dump(preprocessing_dict, f)\n","\n","# DeepFM 모델 정의\n","def build_deposit_deepfm_model(input_dim, categorical_dims, embed_dim=8):\n","    inputs = []\n","    embeddings = []\n","\n","    # Embedding for categorical features\n","    for dim in categorical_dims:\n","        input_layer = Input(shape=(1,))\n","        embedding = Embedding(input_dim=dim, output_dim=embed_dim)(input_layer)\n","        embedding = Flatten()(embedding)\n","        inputs.append(input_layer)\n","        embeddings.append(embedding)\n","\n","    # Numerical features input\n","    numerical_input = Input(shape=(len(numerical_features),))\n","    inputs.append(numerical_input)\n","    embeddings.append(numerical_input)\n","\n","    # Concatenate all embeddings and numerical features\n","    concatenated = Concatenate()(embeddings)\n","\n","    # Deep part of the model\n","    x = Dense(64, activation='relu')(concatenated)\n","    x = Dropout(0.5)(x)\n","    x = Dense(32, activation='relu')(x)\n","    x = Dropout(0.3)(x)\n","    output = Dense(1, activation='sigmoid')(x)\n","\n","    model = Model(inputs=inputs, outputs=output)\n","    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n","\n","    return model\n","\n","categorical_dims = [df[feature].nunique() for feature in categorical_features]\n","model = build_deposit_deepfm_model(len(X_categorical) + len(X_numerical), categorical_dims)\n","early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n","\n","# 모델 학습\n","model.fit(X_categorical + [X_numerical], y, epochs=10, batch_size=32, validation_split=0.2, callbacks=[early_stopping])\n","\n","model.save('deposit_deepfm_model.h5')\n"],"metadata":{"id":"_5ktvc7bpQs8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["user_data_file = '/content/drive/MyDrive/shinhan_data/realistic_korean_financial_user_data.csv'\n","user_data_df = pd.read_csv(user_data_file)"],"metadata":{"id":"a_R5LpbB1rW6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["user_data.head()"],"metadata":{"id":"NTtNzFOK1OTl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","\n","# 기존 카테고리에 없는 새로운 값을 처리하기 위한 함수\n","def encode_with_unknown_handling(feature, encoder, value):\n","    if value in encoder.classes_:\n","        return encoder.transform([value])[0]\n","    else:\n","        # 새로운 값에 대해 '미지정' 또는 다른 대체 값을 사용하도록 처리\n","        return encoder.transform([encoder.classes_[0]])[0]  # 첫 번째 클래스로 대체\n","\n","# 예금 상품 정보를 가져오는 함수\n","def get_deposit_product_info(deposit_id, deposit_products_df):\n","    return deposit_products_df[deposit_products_df['deposit_id'] == deposit_id].iloc[0]\n","\n","# 예측 수행을 위한 전처리 및 데이터 보완\n","def preprocess_and_predict(new_user_data, model, label_encoders, scaler, categorical_features, numerical_features):\n","    # 1. Label Encoding: 새로운 데이터에 대해 이전에 학습된 LabelEncoder 적용\n","    for feature in categorical_features:\n","        if feature in label_encoders:\n","            new_user_data[feature] = new_user_data[feature].apply(lambda x: encode_with_unknown_handling(feature, label_encoders[feature], x))\n","\n","    # 2. Normalize numerical features\n","    new_user_data[numerical_features] = scaler.transform(new_user_data[numerical_features])\n","\n","    # 3. Prepare input for prediction\n","    X_categorical = [new_user_data[feature].values for feature in categorical_features]\n","    X_numerical = new_user_data[numerical_features].values\n","\n","    # 4. Predict using the trained model\n","    prediction = model.predict(X_categorical + [X_numerical])\n","\n","    return prediction\n","\n","# 여러 deposit_id에 대해 예측을 수행하고, 상위 N개의 예금 상품을 추천하는 함수\n","def recommend_top_n_deposit_products(new_user_data, model, label_encoders, scaler, categorical_features, numerical_features, deposit_products_df, top_n=5):\n","    predictions = []\n","\n","    for deposit_id in deposit_products_df['deposit_id'].unique():\n","        # 현재 deposit_id에 대한 예금 상품 정보 추가\n","        deposit_info = get_deposit_product_info(deposit_id, deposit_products_df)\n","        new_user_data['deposit_id'] = [deposit_id]\n","        new_user_data['deposit_interest_rate'] = [deposit_info['deposit_interest_rate']]\n","        new_user_data['term_months'] = [deposit_info['term_months']]\n","        new_user_data['min_deposit_amount'] = [deposit_info['min_deposit_amount']]\n","        new_user_data['max_deposit_amount'] = [deposit_info['max_deposit_amount']]\n","\n","        # 예측 수행\n","        prediction = preprocess_and_predict(new_user_data, model, label_encoders, scaler, categorical_features, numerical_features)\n","        predictions.append((deposit_id, prediction[0][0]))\n","\n","    # 예측 확률을 기준으로 상위 N개의 예금 상품을 정렬하여 선택\n","    top_n_predictions = sorted(predictions, key=lambda x: x[1], reverse=True)[:top_n]\n","\n","    return top_n_predictions\n","\n","# 새로운 사용자 데이터\n","new_user_data = pd.DataFrame({\n","    'user_id': [100001],  # 새 유저의 ID\n","    'gender': [0],  # 성별\n","    'region': ['서울'],  # 지역\n","    'occupation': ['대기업 직원'],  # 직업\n","    'late_payment': [1],  # 연체 여부\n","    'financial_accident': [0],  # 금융 사고 여부\n","    'age': [24],  # 나이\n","    'annual_income': [3500],  # 연간 소득\n","    'debt': [800],  # 부채\n","    'credit_score': [800],  # 신용 점수\n","    'annual_spending': [1000],  # 연간 소비\n","    'num_cards': [2],  # 보유 카드 수\n","    # 'min_balance': [100]  # 최소 잔액\n","})\n","\n","# Top 5 예금 상품 추천\n","top_5_deposit_products = recommend_top_n_deposit_products(new_user_data, model, label_encoders, scaler, categorical_features, numerical_features, deposit_products_df, top_n=5)\n","print(\"Top 5 추천 예금 상품 및 확률:\")\n","for deposit_id, prediction in top_5_deposit_products:\n","    print(f\"예금 상품 ID: {deposit_id}, 선택 확률: {prediction}\")\n"],"metadata":{"id":"N45FMCiEsyEB"},"execution_count":null,"outputs":[]}]}